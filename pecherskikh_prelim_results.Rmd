---
date: "Arthur Pecherskih (*last updated on* `r format(Sys.time(), '%d.%m.%y')`)"
title: "**Аннотации статей российских социологов: промежуточные результаты**"
output:
  html_document:
    theme: cosmo
    toc: yes
    toc_float: yes
  pdf_document:
    toc: yes
---


<style type="text/css">

h1.title {
  height: 10px;
  font-size: 18px;
}

h4.author {
  font-size: 18px;
}

</style>




```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      cache = TRUE,
                      message = FALSE,
                      warning = FALSE)
```




```{r, include=F}
library(tidyverse)
library(stringr)
library(readr)
library(xlsx)
library(kableExtra)
library(tidylo)
library(tidytext)
library(plotly)

library(ggdendro)

library(quanteda.textmodels)
library(stopwords)
library(tm)

library(ggtext)

library(quanteda)
library(topicmodels)
library(ldatuning)
library(stm)
library(ca)
library(FactoMineR)
library(factoextra)

library(GGally)
library(igraph)
library(compositions)
library(directlabels)
```


## **Описание данных**


Для анализа были собраны метаданные статей из 18 журналов по социологии, входящих в ядро РИНЦ и перечень ВАК, издающих статьи на русском языке (по состоянию на март 2023 года). Я предполагаю, что сочетание этих параметров производит список легитимных изданий, репрезентирующих поле российской социологии. Из изначального списка, соответствующего этим критериям, были исключены журналы *Крестьяноведение* и *Высшее образование в России* из-за их узких предметных областей, пересекающихся с другими дисциплинарными полями. Всего было собрано **19,559 статей**, из которых для **13,262** были также извлечены тексты аннотаций (в анализе это число сократится ввиду длин текстов и проч.). Основными источниками данных служили архивные секции, представленные на сайтах журналов. Таблица ниже содержит описание полученной базы данных:


```{r, echo=F,warning=F,message=FALSE}
data <- read.csv("data1704.csv")
abstracts <- data %>% 
  filter(!is.na(article_abstract)) %>%  ## 19,557
  filter(article_abstract != "") %>% ## 15,812
  filter(article_abstract != " ") %>% ## 15,810
  filter(!str_detect(article_abstract, "ецензия|ЕЦЕНЗИЯ")) %>% ## 15,588
  filter(article_abstract != "-") %>%  ## 15,151
  filter(article_abstract != "нет") %>%  ## 14,958
  filter(article_abstract != "Читать в формате PDF>>") %>% ## 14,870
  filter(article_abstract != "***") %>%  ## 14,823
  filter(article_abstract != "  ") %>% ## 14,823
  filter(!str_detect(article_name, "ецензия|ЕЦЕНЗИЯ")) %>% ## 14,749
  filter(str_detect(article_abstract, "а|б|в|г|д|е|ё|ж|з|и|к|л|м|н|о|п|р|с|т|у|ф|х|ц|ч|ш|щ|ъ|ы|ь|э|ю|я|А|Б|В|Г|Д|Е|Ё|Ж|З|И|К|Л|М|Н|О|П|Р|С|Т|У|Ф|Х|Ц|Ч|Ш|Щ|Ъ|Ы|Ь|Э|Ю|Я")) ## 13,308

abstracts <- abstracts %>% 
  anti_join(abstracts %>%
              count(article_abstract) %>%
              arrange(desc(n)) %>% 
              filter(n > 1)) ## 13,262

#############################
###### первая таблица: ######
#############################

### число статей:
data %>% 
  count(journal_name) %>% 
  arrange(desc(n)) %>% 
  left_join(

### годы:
    data %>%
      group_by(journal_name) %>%
      summarise(min_year = min(year, na.rm = T),
                max_year = max(year, na.rm = T)) %>%
      mutate(period = str_c(min_year, "—", max_year)) %>%
      select(-min_year,
             -max_year)) %>% 
  
    left_join(

### у скольки есть абстракты
    
    abstracts %>%
      count(journal_name) %>%
      rename(n_abstracts = n)) %>% 
  
  
  mutate(journal_name = str_replace_all(journal_name,
                                        "Мониторинг общественного мнения",
                                        "Мониторинг общественного мнения: экономические и социальные перемены")) %>% 
    mutate(journal_name = str_replace_all(journal_name,
                                        "Вестник РУДН",
                                        "Вестник РУДН. Серия: социология")) %>% 
  left_join(

### кол-во РИНЦ
    (read.csv("to_load2.csv"))[1:18,c(1,5)] %>% 
  `colnames<-`(c("journal_name", "n_RISC"))) %>% 
  left_join(read.xlsx("to_load2205.xlsx", sheetIndex = 1)[1:18,c(2, 4)] %>%
              `colnames<-`(c("journal_name", "period0"))) %>% 
  select(journal_name, n_RISC, n, period0, period, n_abstracts) %>% 
#  mutate(n_RISC = cell_spec(n_RISC, background=ifelse(n_RISC < n, "white", "coral1"))) %>% 
  mutate(n = cell_spec(n, background=ifelse(n +100 > n_RISC, "white", "coral"))) %>% 
  
  `colnames<-`(c("название журнала", "статей в РИНЦ", "статей собрано", "год основания", "собранный период", "статей с аннотациями")) %>%
  kbl(booktabs = T, linesep = "", escape=FALSE) %>%
  kable_styling(full_width = F) %>%
  column_spec(1, bold=T)
```




Хотя основным материалом для дальнейшего анализа стали тексты аннотаций, стоит заметить, что различия в тематических/методологических журнальных ориентациях обнаруживается и при сравнении наиболее частотных ключевых слов (см. таблицу ниже). Стоит отметить, что два журнала, *"Социологическое обозрение"* и *"Вестник ТГУ"*, отличаются от прочих наличием высокочастотных ключевых слов, отсылающих к конкретным людям, в том числе не относящихся к социологическому дисциплинарному канону (н. Ханна Арендт в списке для *"СоцОбоза"*). Журналы, посвященные более узким темам, вроде *"Демографического обозрения"* или *"Экономической социологии"*, также показывают свое отличие на уровне ключевых слов. Здесь же стоит обратить внимание на довольно низкий порядок частотностей (относительно числа журнальных статей), который может свидетельствовать как о (1) разнообразии тем, поднятых в статьях, так и о (2) том, что сами журналы (члены их редколлегий) не стремятся сделать из указания ключевых слов институированную практику, заранее ограничивающую их выбор.



```{r, echo=F,warning=F,message=FALSE}
abstracts %>% 
  filter(!is.na(article_keywords)) %>% 
  filter(article_keywords != "") %>%
  mutate(article_keywords = str_squish(str_replace_all(article_keywords, "\\;", "\\,"))) %>% 
  select(journal_name, year, article_keywords) %>%
  unnest_tokens(keyword, article_keywords, token = 'regex', pattern=",") %>%
  mutate(keyword = str_squish(tolower(keyword))) %>% ## 96,622
  mutate(keyword = str_replace_all(keyword, "ё", "е")) %>% 
  count(journal_name, keyword) %>%
  group_by(journal_name) %>% 
  rename(n_words = n) %>% 
  filter(str_detect(keyword,
                    "а|б|в|г|д|е|ё|ж|з|и|к|л|м|н|о|п|р|с|т|у|ф|х|ц|ч|ш|щ|ъ|ы|ь|э|ю|я|А|Б|В|Г|Д|Е|Ё|Ж|З|И|К|Л|М|Н|О|П|Р|С|Т|У|Ф|Х|Ц|Ч|Ш|Щ|Ъ|Ы|Ь|Э|Ю|Я")) %>%
  mutate(keyword = str_remove_all(keyword, "\\»|\\«")) %>% 
  slice_max(order_by = n_words,
            n = 10) %>% 
  filter(n_words > 3) %>%
  ungroup() %>% 
  mutate(freq = str_c(keyword, " (", n_words, "),")) %>% 
  group_by(journal_name) %>% 
  summarize(keywords = str_c(freq, collapse = " ")) %>% 
  ungroup() %>% 
  mutate(keywords = str_remove_all(keywords, ",$")) %>% 
  
  left_join(data %>% 
              count(journal_name)) %>% 
  arrange(desc(n)) %>% 
  select(-n) %>% 
  
  left_join(abstracts %>%
              filter(!is.na(article_keywords)) %>%
              filter(article_keywords != "") %>%
              mutate(article_keywords = str_squish(str_replace_all(article_keywords, "\\;", "\\,"))) %>%
              select(journal_name, year, article_keywords) %>%
              unnest_tokens(keyword, article_keywords, token = 'regex', pattern=",") %>%
              mutate(keyword = str_squish(tolower(keyword))) %>% ## 96,622
              mutate(keyword = str_replace_all(keyword, "ё", "е")) %>%
              count(journal_name, keyword) %>%
              group_by(journal_name) %>%
              rename(n_words = n) %>%
              filter(str_detect(keyword,
                                "а|б|в|г|д|е|ё|ж|з|и|к|л|м|н|о|п|р|с|т|у|ф|х|ц|ч|ш|щ|ъ|ы|ь|э|ю|я|А|Б|В|Г|Д|Е|Ё|Ж|З|И|К|Л|М|Н|О|П|Р|С|Т|У|Ф|Х|Ц|Ч|Ш|Щ|Ъ|Ы|Ь|Э|Ю|Я")) %>%
              mutate(keyword = str_remove_all(keyword, "\\»|\\«")) %>%
              count(journal_name) %>%
              rename(abstracts_with_keywords = n), by = "journal_name") %>% 
  mutate(journal_name = str_c(journal_name, " (", abstracts_with_keywords, ")")) %>% 
  select(-abstracts_with_keywords) %>%
  `colnames<-`(c("название журнала (число указанных ключевых слов всего)", "наиболее частотные ключевые слова")) %>%
  
  kable() %>% 
  kable_styling(full_width = F) %>% 
  column_spec(1,
              bold=T)
```

---  


## **Результаты - 1: *Wordfish model* **


Модель wordfish изначально была разработана для автоматического атрибутирования политических взглядов (левых/правых, авторитарный/либертарный) человека или организации, стоящих за определенным текстом (Slapin and Proksch, 2008). В ее основе находится предположение о пуассоновском распределении частотностей слов в корпусе текстов, позволяющее сконструировать для последнего одномерную шкалу. Согласно недавнему предположению немецких исследователей, эта же модель способна уловить "polar opposition between qualitative work versus quantitative work associated with different schools of thought" (Schwemmer & Wieczorek, 2020, p. 10). При выборе модели авторы отталкивались от необходимости получить веса не только на уровне слов, но и на уровне документов. Подобные оценки могут быть также получены с помощью различных подходов к моделированию тем (н. probabilistic topic models или structural topic models), однако они требуют априорного решения о количестве извлекаемых измерений, усложняя стоящую перед исследователем задачу (*ibid*). В следующем разделе один из этих методов, correlated topic models, используются для получения иной по форме картины того, что происходит в собранном корпусе.



Помимо выбора корректного набора текстовых данных, залогом успеха в корпусной лингвистике является их корректная предобработка. При выборе тех или иных шагов по предобработке корпуса я ориентировался на действия оригинальное исследование немецких авторов (Schwemmer & Wieczorek, 2020, p. 9) с поправкой на специфику русского языка. Итак, в первую очередь из аннотационного корпуса были удалены аннотации, относящиеся к таким публикационным жанрам, как рецензия, круглый стол, перевод, сообщение о семинаре и т. п. Далее, из текстов была удалена не относящаяся к аннотации информация: например, к ней относились ключевые слова, DOI и англоязычная версия аннотации. Здесь же из корпуса были удалены слишком длинные и слишком короткие аннотации. Следующим классическим шагом стала лемматизация текстов с помощью программы *mystem* (Segalovich, 2003). Лемматизация приводит каждое слово к его основе (н. "социологию" -> "социология", "выделяет" -> "выделять"), анализируя в том числе контекст его употребления, что позволяет провести контекстное снятие омонимии (ситуация, когда обладающие одинаковым звучанием и написанием слова обладают разным значением). Следующим шагом стал поиск коллокаций, - устойчивых в употреблении языковых конструкций (н. "культурный капитал", "регрессионный анализ"). Их уточнение должно серьезно повышать качество модели: конечно, семантическая разница между аргументами "культурный капитал" и "культурный"/"капитал" велика, и отсутствие этого шага затруднило бы атрибуцию гипотетической статьи, в которой обсуждался бы именно "культурный капитал". Заключительными шагами после приведения корпуса к виду "мешка слов" (*bag-of-words*, формат, не учитывающий порядок слов и грамматику, при этом сохраняющий информацию о частотности слов) стала нормализация написаний (устранена разница в словах с "ё" и "е"), удаление стоп-слов (слов, не несущих самостоятельной смысловой нагрузки, н. предлоги) и очень редких слов, встречающихся менее чем в 50 аннотациях (проверка других порогов не выявила серьезных различий в результатах).



Как уже было отмечено, состав корпуса не менее важен, чем шаги по его подготовке к анализу. Поскольку модель Wordfish конструирует лишь одно измерение, то лексика, характерная для какой-либо узкой темы, будет неизбежно задавать "тон" всей шкале. Источником таких искажений в результатах является включение в исходную выборку журналов, в чьем фокусе находятся относительно редкие темы, не представленные в прочих изданиях. Для наглядности, ниже последовательно представлены характеристики нескольких моделей, для каждой из которых соблюдался описанный выше порядок предобработки, но различался входной корпус текстов. Первым я предлагаю взглянуть на результаты модели, которая в качестве входных данных получила 2,829 параметров (токенов) 12,075 аннотаций (605,308 слов суммарно).


```{r, echo=F, fig.align='center'}
rm(list = ls())
wf301_terms <- read.csv("present_wf18_with_coll.csv")
wf301_groups <- read.csv("present_wf18_thetas.csv")

wf301_groups %>%   
  ggplot(aes(theta, reorder(name, theta))) +
  geom_boxplot() +
  theme_minimal() +
  labs(y = "",
       title = "<span style='font-size:12pt'>**Решение на уровне журналов/аннотаций (18)**<br><span style='font-size:10pt'><i>theta</i> - значение для каждой аннотации") +
  theme(plot.title = element_markdown())
```





Предложенное на графике выше распределение показывает, что журналы *"Демографическое обозрение"*, *"Вестник ТГУ"* и *"Социологическое обозрение"*, занимающие полярные позиции, сильно отличаются от прочих журналов по используемой лексике. При этом характерно, что сходство последних двух изданий было замечено еще в отношении ключевых слов, - это журналы, в которых часто предметом обсуждения становится история социологии и социологическая теория (*"Вестник"*, как становится ясно из названия, публикует статьи не только по социологии, но и по философии и политологии). Задаваемое этими тремя журналами шкалирование всех прочих журналов не имеет смысла, т.к. ранжирует их публикации от "теоретического" полюса к "демографическому", - такой континуум в дисциплине точно не наблюдается.


```{r, echo=F, fig.align='center'}
for(i in c(1:nrow(wf301_terms))){
  
  if(wf301_terms[i,1] %in% c("качественный", "количественный", "экономический социология",
                             
                             "факторный анализ", "логистический", "регрессия", "статистический данные", "опросный", "база данные", "моделирование", "перепись", "телесный", "дискурс", "ритуал", "прекариат", "интеракция", "гендер", "этнографический",
                             
         "отечественный социология", "российский социолог", "коррупция", "нко", "капитализм", "социальный порядок",  "орган власть", "дюркгейм", "вебер", "маркс", "сорокин", "социальный капитал", "культурный капитал", "наша страна", "виртуальный", "молодежь", "динамика", "акторный-сетевой теория", "российский социология", "отечественный социология", "бурдие", "росстат", "удовлетворенность", "регрессионный анализ", "дискуссия", "онтология", "эпистемология", "шмитт", "алкоголь", "трудоспособный", "сакральный", "вич", "патриотизм", "официальный статистика", "проблема", "статья", "результат", "подход", "категория", "свобода", "рмэз", "рынок труд", "практика", "исследование", "данные")){
    wf301_terms[i,4] = wf301_terms[i,1]
  }
  else {wf301_terms[i,4] = ""}
}


(wf301_terms %>%
   filter(beta < 4.5 & beta > -4.5) %>%
   ggplot(aes(beta,
              psi#,
              #text = paste(
              #  "<b>Word: </b>", feature)
              )) +
    geom_point(size = 0.1,
              color = "coral1",
              alpha = 0.7) +
    theme_minimal() +
    geom_text(aes(label = ...4),
                    color = "black",
                    size = 2.4,
                    fontface = "italic"
            ) +
    labs(title = "<span style='font-size:12pt'><b>Оцененные позиции слов (выборка -- все 18 журналов)</b></span><br><span style='font-size:8pt'><b>Параметры модели:</b> включены токены с общей частотностью > 50 по всему корпусу и коллокации с частотностью > 30<br><b>Интерпретация:</b> лексика <i>СоцОбоза</i> (-) и <i>Демографического Обозрения</i> (+) слишком сильно отличается от всего корпуса,<br>лишая шкалу смысла",
         x = "*estimated beta* (результат одномерного шкалирования)",
         y = "*estimated psi* (частотность слов)") +
    theme(plot.title = element_markdown(),
          axis.title.y = element_markdown(size = 8),
          axis.title.x = element_markdown(size = 8)))
```

---

В последующих моделях я последовательно исключал из входных данных те журналы, которые оказывались обладателями исключительно нехарактерной для прочих журналов лексики. Так, ниже представлены модели с 15 (без *"СоцОбоза"*, *"Вестника ТГУ"* и *"Демографического обозрения"*; 9,828 аннотаций при 2,759 токенах) и 14 журналами (в дополнение к прошлому, без журнала *"Женщина в российском обществе"*; 9,184 аннотации при 1,452 токенах).


```{r, echo=F, fig.align='center'}
rm(list = ls())
wf302_terms <- read.csv("present_wf15_terms.csv")
wf302_groups <- read.csv("present_wf15_groups.csv")

wf302_groups %>%   
  ggplot(aes(theta, reorder(name, theta))) +
  geom_boxplot() +
  theme_minimal() +
  labs(y = "",
       title = "<span style='font-size:12pt'>**Решение на уровне журналов/аннотаций (15)**<br><span style='font-size:10pt'><i>theta</i> - значение для каждой аннотации") +
  theme(plot.title = element_markdown())

rm(list = ls())
wf302_terms <- read.csv("present_wf_14_colls_terms.csv")
wf302_groups <- read.csv("present_wf_14_colls_groups.csv")

wf302_groups %>%   
  ggplot(aes(theta, reorder(name, theta))) +
  geom_boxplot() +
  theme_minimal() +
  labs(y = "",
       title = "<span style='font-size:12pt'>**Решение на уровне журналов/аннотаций (14)**<br><span style='font-size:10pt'><i>theta</i> - значение для каждой аннотации") +
  theme(plot.title = element_markdown())
```

---

Оба эти решения также не улавливают предполагаемую оппозицию качественного/количественного (качественный *"Laboratorium"* и количественный *"Социология. 4М"* оказались не только рядом, но и на конце шкалы в обоих случаях). Примечательно, что исключение ивановского журнала *"Женщина в российском обществе"* слабо отразилась на положении прочих журналов - можно предположить, что, в отличие от трех исключенных ранее журналов, это издание не исчерпывающе объясняет возникающую шкалу.


Дальнейшие эксперименты с составом входных данных (дальнейшее исключение журналов, фильтрация выпусков по годам выпуска и проч.) не дали более интерпретируемых результатов. В связи с этим была предпринята попытка сконструировать модель, в которой частотности слов сгруппированы не для отдельных статей, но для журналов целиком. Это отчасти обесценивает интенцию, с которой модель применялась для шкалирования аннотаций раньше: получить оценку как документов (аннотаций), так и их источников - журналов (Schwemmer & Wieczorek, 2020, pp. 9-10). Главный минус такого решения - невозможность вернуться с имеющимися весами к метаданным статей для того, чтобы попробовать объяснить вариацию в них с помощью формальных характеристик (н. аффилиации автора). Тем не менее, и такое решение имеет ценность, т. к. дает представление о распределении журнальных корпусов по полученной шкале.



```{r, echo=F, fig.align='center'}
rm(list = ls())
load("attempt2april.RData")
data.frame(theta = wf_abstracts3$theta,
           docs = as.numeric(wf_abstracts3$docs)) %>%
  left_join(ids3 %>% 
              `colnames<-`(c("name", "docs"))) %>% 
  
  ggplot(aes(theta, reorder(name, theta))) +
  geom_bar(stat = "identity") +
  theme_minimal() +
labs(x = "theta (<i>больше = более количественный</i>)",
     y = "",
       title = "<span style='font-size:12pt'>**Решение на уровне журналов (14)**<br><span style='font-size:10pt'><i>theta</i> - значение для журнала<br>частотности слов посчитаны для журналов, а не аннотаций") +
  theme(plot.title = element_markdown(),
        axis.title.x = element_markdown(size = 9))
```

---

Полученное таким образом распределение поддается удобной интерпретации, т. к. качественный и количественный журналы, *Laboratorium* (согласно описанию журнала на его сайте, у него нет "строгих ограничений" касательно присылаемых материалов, однако одно из его направлений включает именно ["качественные методы социальных исследований (методологическая дискуссия, методологические эксперименты)"](https://www.soclabo.org/index.php/laboratorium/about)) и *Социология. 4М* (описание журнала на его сайте гласит: ["Направленность журнала делает его уникальным специализированным изданием, посвященным проблемам методологии и методов социологических исследований, вопросам сбора, измерения и анализа социологических данных, построению математических моделей социальных процессов."](https://www.jour.fnisc.ru/index.php/soc4m)), наконец оказались разведены по разным полюсам спектра. Соответственно, прочие журналы получают свои веса в зависимости от их близости их лексики к лексике того или прочего полюса.



```{r, echo=F, fig.align='center'}
scat.plot3 <- data.frame(beta = wf_abstracts3$beta,
                         psi = wf_abstracts3$psi,
                         lem = wf_abstracts3$features)


for(i in c(1:nrow(scat.plot3))){
  
  if(scat.plot3[i,3] %in% c("количественный", "качественный", "дискурс",
                            "логистический", "статистически", "шкала", "индекс", "факторный", "валидность", "патриотизм", "цифровизация", "межэтнический", "молодежь", "анкетирование",
                            "феминистский", "инклюзивный", "наблюдение", "кейс", "этнографический", "тело", "конструирование", "полевой", "интеракция", "язык",
                            "вебер", "дюркгейм", "маркс", "сорокин",
                            
                            "метод", "контекст", "анализ", "российский", "подход", "практика", "результат", "конфликт", "социальный")){
    scat.plot3[i,4] = scat.plot3[i,3]
  }
  else {scat.plot3[i,4] = ""}
  
}

(scat.plot3 %>% 
    filter(psi > 0 & beta > -1.5 & beta < 1.7) %>%
    ggplot(aes(beta,
               psi,
               text = paste("Word: ", lem))) +
    geom_point(color = "coral1", size = 0.1, alpha = 0.4) +
    geom_text(aes(label = V4), fontface = "italic", size = 2.8, color = "black") +
    theme_minimal() +
    labs(title = "<span style='font-size:12pt'><b>Оцененные позиции слов (14 журналов)</span><br><span style='font-size:10pt'>частотности слов посчитаны для журналов, а не аннотаций | без коллокаций<br>оставлены токены с частотностью > 50",
         x = "вес токена (<i>больше = более количественный</i>)",
         y = "фиксированный эффект токена<br>(<i>больше = частотнее</i>)") +
        theme(plot.title = element_markdown(),
          axis.title.y = element_markdown(size = 8),
          axis.title.x = element_markdown(size = 8)))
```


---

На графике выше наблюдения (слова) - это аргументы полученной модели. По оси x отложены веса (шкалированные значения): слова, одинаково часто встречающиеся во всех журнальных корпусах, распределены около 0 ("анализ", "подход", "результат"), полярные же значения занимают токены, характреные для журналов *"Laboratorium"* и *"Социология. 4М"* (см. пред. график). Токен "качественный" является более частотным, чем "количественный", однако они занимают практически неотличимое положение на шкале x. Так, оба этих токена являются плохими индикаторами используемой в статье методологии; к такому же заключению приходят авторы оригинальной статьи, где модель применяется к англоязычным данным (Schwemmer & Wieczorek, 2020, p. 13).


Подписи даны лишь самым характерным токенам, так, чтобы полученное пространство было интерпретируемо. Левая часть спектра, вкключающая токены "этнографический", "полевой", "наблюдение" и "кейс" представляет качественный полюс. Примечательно, что к нему же тяготеет токен "вебер": немецкий классик был автором проекта "понимающей социологии", как раз связанной с качественной методологией. Говоря о темах исследований, расположенных в этом конце, стоит обратить внимание на токены "тело", "интеракция", "феминистский", "конструирование". Лексика на противоположном конце спектра обычна для количественных исследований: "шкала", "индекс", "валидность" и проч. Здесь тематическими токенами являются "цифровизация", "патриотизм", "молодежь".




## **Результаты - 2: *correlated topic model* **


Полученное в предыдущем блоке с помощью модели Wordfish решение имеет понятные ограничения. Во-первых, тяжело отделить эффект специфичной лексики полярных журналов от их тематической специфики. Может быть и так, что эти журналы действительно отличаются от всего остального корпуса, а количественная/качественная лексика в них - лишь одна из составляющих этой разницы, что приводит к искажению результатов. Следовательно, можно подвергнуть сомнению и полученное распределение журналов: конечно, *"Экономическую социологию"* тяжело назвать "качественным" журналом; скорее, речь идет о близости используемой в его аннотациях лексики (не только связанной с методами) к лексике *"Laboratorium"*. Во-вторых, финальное решение ограничено тем, что оно предлагает веса только для журналов, не позволяя оценивать отдельные статьи.


По этим причинам в качестве второго метода анализа аннотационного корпуса было использовано моделирование тем. Это большое семейство алгоритмов, также основанных на распределении частотностей слов по документам, производящее некоторое количество "тем" (т.е. групп слов, чье появление в тексте ассоциировано друг с другом) и оценку того, насколько каждая тема представлена в том или ином документе (DiMaggio et al., 2013, p. 577). Главным преимуществом этого метода заключается в том, что он позволяет анализировать большие объемы данных при относительно низкой вычислительной требовательности; преимущество по сравнению с использованной выше моделью Wordfish - в том, что моделирование тем производит не одну "тематическую" шкалу (континуум), но множество. Благодаря этому результаты в меньшей степени подвержены влиянию какого-либо набора документов с радикально отличающейся от прочих документов лексикой: здесь эти документы получат свою собственную "тему" (см. ниже на ассоциацию темы "демография" и *"Демографического обозрения"*). название и характеристику сгенерированным темам присваивает исследователь путем подробного изучения как слов, относящихся к той или иной теме, так и документов, в которых та или иная тема наиболее выражена.


Тексты аннотаций как данные для моделирования тем исторически были важны для развития всего семейства методов: ранний пример использования correlated topic model (CTM) был основан на корпусе аннотаций из журнала *"Science"* (Blei & Lafferty, 2007). Обычно моделирование тем используют для описания исследовательского поля и его динамики во времени; отдельным инструментальным назначением этих методов может служить определение теоретических теоретических пробелов (Westgate et al., 2015). Как правило, входящий корпус в такого рода исследованиях состоит не из дисциплинарной области, а из какой-либо ее части, поскольку так авторы могут проявить большую экспертность по теме и оценить качество получаемых решений (см. примеры про conservation science в Westgate et al., 2015; социальные движения в Lindstedt, N. C. 2019; лидерство в образовании в Wang et al. 2017). На это также влияет то, что естественное ограничение любого подхода к моделированию тем, - необходиомсть предоставить алгоритму конкретное число тем, которое следует извлечь из корпуса, - становится более критичным при работе с корпусами большого размера и/или большим количеством потенциальных тем. В отношении социологии целиком, тем не менее, ранее было предпринято несколько попыток сконструировать тематический ландшафт. Для этого, например, использовали аннотации статей из *"American Journal of Sociology"* за 1921-2016 годы (Giordan et al., 2018). В другой работе моделироавние тем в большом корпусе аннотаций социологических статей стало лишь первым шагом для оценки зависимости дисциплины от экономики (Daoud & Kohl, 2015). 



При выборе конкретного метода для моделирования тем в собранном аннотационном корпусе я ориентировался на аргументацию, предложенную в исследовании "тем" в исследоавниях высшего образования (Daenekindt & Huisman., 2020). Наиболее распространенный метод моделирования тем - Latent Dirichlet Allocation (LDA), - предполагает независимость появления тем в документе друг от друга. Это серьезное допущение, влияющее на результаты: то, что на языке метода понимается под "темами", в человеческих текстах редко независимо друг от друга. Скажем, тема "количественные методы" (со словами "регрессия", "шкала" и т.д.) с куда большей вероятностью будет появляться вместе с темой "демография" (со словами "смертность", "рождаемость", "продолжительность"), чем с темой "гендерное неравенство" (слова "стереотип", "неравенство", "насилие" и проч.). Correlated topic model (CTM) ослабляет условие неезависимости между темами, допуская корреляцию между темами (Blei & Lafferty, 2007). Оригинальный алгоритм и его реализации требуют больших вычислительных мощностей, из-за чего для инициализации модели был использован спектральный метод, реализованный в пакете `stm` в R (Roberts et al. 2019).



Наконец, процесс предобработки текстов для моделирования тем несколько отличается от того, что был описан выше в отношении модели Wordfish. Поскольку результат не зависит от вкраплений нехарактерной для всего корпуса лексики, для анализа использовались все 18 журналов. Для большей надежности данных было решено ограничить период публикации статей с 2010 по 2022 годы. Далее, из данных были удалены все не-аннотационные части текстов (DOI, ключевые слова) и тексты, относящиеся к жанрам рецензий, обзоров, предваряющих выпуски редакторских обращений и т. п. Как и в прошлой секции, написание слов было нормализовано ("е" и "ё"). Программа mystem (Segalovich, 2003) была использована для лемматизации текстов и определения частей речи. Последнее было сделано для того, чтобы сделать корпус, состоящий исключительно из существительных, - это самая семантически насыщенная часть речи в языке, что позволяет повысить качество и интерпретируемость получаемых тем (Martin & Johnson, 2015). Наконец, из корпуса был удален 1% самых частотных слов (те, что в распределении слов, получаемом из результатов Wordfish, находились сверху: конституируемые ими темы (н. "лексика для начала аннотации" со словами "статья", "феномен" и т. д.) являются инструментальными и не представляют интереса при описании дисциплинарного поля) и те слова, что встречаются менее чем в 1% всех документов (оба этих шага взяты из Daenekindt & Huisman., 2020). наконец, данные были приведены к формату матрицы термов-документов: она включала 9,217 документов (аннотаций) при 789 аргументов.




```{r, echo=F, fig.align='center'}
rm(list = ls())
comparison_data <- read.csv("comparison_data2305.csv")
#write.csv(comparison_data,
#          "comparison_data2305.csv",
#          row.names = F)
comparison_data %>%
  mutate(topic_order2 = str_remove_all(topic_order, "Topic"),
         model_name2 = as.numeric(str_remove_all(model_name, "ctmFit")),
         model_name = str_replace_all(model_name, "ctmFit", "*k* = ")) %>% 
  ggplot(aes(semantic_coherence, exclusivity)) +
  geom_point() +
  facet_wrap(~model_name2) +
  #theme_minimal() +
  labs(x = "semantic coherence (*больше - лучше*)",
       y = "exclusivity (*больше - не всегда лучше*)",
       title = "**Сравнение результатов *CTM* с разным числом тем (*k*)**<br><span style='font-size:10pt'>*max. EM iterations* = 300") +
  theme_minimal() +
  theme(plot.title = element_markdown(),
        strip.text = element_markdown(),
        axis.title.x = element_markdown(),
        axis.title.y = element_markdown())
```

---


Необходимость выбора числа тем является одним из главных направлений критики любого подхода к моделированию тем и причиной, почему в уже неоднократно процитированной статье о методологическом разделении социологии авторы отказались от этой опции (Schwemmer & Wieczorek, 2020). Говоря более предметно, сложность состоит в том, что нет "правильного" числа тем, - число выбирается исходя из интерпретируемости результатов и исследовательских вопросов (DiMaggio et al. 2013). По этой причине процесс выбора параметра числа тем (k) неизбежно включает построение моделей с разным числом тем и сочетание автоматических и "ручных" методов их оценки. График выше показывает, как в моделях с разным параметром k изменяется распределение сгенерированных тем по осям семантической связности (устойчивость использования слов в теме; бОльшие значения сигнализируют об устойчивости модели/тем, низкие - о том, что модель/тема может состоять из подтем) и эксклюзивности (насколько складываемая в тему лексика отличительна от лексики других тем). Авторы прошлых исследований аннотаций социологических статей останавливались на значении k равном 15 (Daoud & Kohl, 2015; стоит заметить, что авторы не обсуждают это подробно, ссылаясь на то, что приблизительно такое же количество тем было в исследованиях Пола ДиМаджио и коллег (2013) и Нила Флигстина(2014), однако их исследования не касались анализа дисциплинарных полей) и 30 (Giordan et al., 2018; авторы оценивали модели от 2 до 50 тем и оценивали log-likelihood моделей. Важно, что авторы исследовали данные, покрывающие более чем вековую историю американской социологии, из-за чего некоторые темы остались в прошлом). Я остановился на значении k = 24: именно это число обеспечило сочетание высокой интерпретируемости (для этого использовался параметр FREX: средняя оценка порядка слова на основе его частотности (FRequency) и эксклюзивности (EXclusivity), взято из Daenekindt & Huisman, 2020) и создало своеобразный "запас" тем, которые оказались неинтерпретируемыми/смешанными (это обычное дело в моделировании тем: несоизмеримость того, как тексты видит человек и алгоритм проявляется в таких темах наиболее ясно).


Таблица ниже содержит наиболее характерные для тем слова (извлеченные не только с помощью метрики FREX) и присвоенные им названия. В тех случаях, когда характерной лексики было недостаточно для атрибутирования темы, были также рассмотрены документы, отличавшиеся их наибольшей представленностью.


```{r, echo=F}
#proportions_table <- make.dt(ctmFit24)  
#(summarize_all(proportions_table, mean) %>% 
#  t() %>% 
#  data.frame())[-1,] %>% 
#  data.frame(share = .) %>% 
#  bind_cols(descr) %>% 
#  mutate(Присвоенные.названия = str_c(Присвоенные.названия, " (", round(share, 2), "%)")) >%
#  select(-share) %>% 
#  write.csv("topics_table.csv", row.names = F)


rm(list = ls())
read.csv("topics_table.csv") %>% 
  `colnames<-`(c("Номер темы", "Присвоенные названия<br>(% в корпусе)", "Характерная лексика")) %>%
  mutate(`Характерная лексика` = str_replace_all(`Характерная лексика`, "PROB", "<b>PROB</b>"),
         `Характерная лексика` = str_replace_all(`Характерная лексика`, "FREX", "<br><b>FREX</b>"),
         `Характерная лексика` = str_replace_all(`Характерная лексика`, "LIFT", "<br><b>LIFT</b>"),
         `Характерная лексика` = str_replace_all(`Характерная лексика`, "SCORE", "<br><b>SCORE</b>")) %>% 
  kbl(booktabs = T, linesep = "", escape=FALSE) %>%
  kable_styling(full_width = F) %>%
  column_spec(2, bold=T)
```

---
 
Ввиду того, что CTM представляет каждый документ как сочетание тем, можно оценить то, какие из тем чаще всего встречаются вместе. Для этого, следуя авторам исследования аннотаций в публикациях о высшем образовании (Daenekindt & Huisman, 2020), было применена иерархическая кластеризация данных формата документы-темы (9,205 документов при 24 темах). Композиционная природа матрицы термов-документов была учтена с помощью (1) трансформации матрицы с Aitchison composition scales и (2) ковариационной матрицы (Van den Boogaart & Tolosana-Delgado, 2013). Для измерения расстояния между документами был использован метод Варда (Ward). Результаты кластеризации представлены на дендрограмме ниже:




```{r, echo=F, fig.align='center'}
#clustdata <- ctmFit24$theta %>%
#  data.frame() %>%
#  `colnames<-`(c("смешано (0.02%)", "регионы (0.03%)", "язык_дискурс (0.04%)", "методология_смешано (0.07%)", "потребление (0.02%)", "безопасность (0.04%)", "демография (0.04%)", "образование_школа (0.02%)", "методология_2_выборки (0.05%)", "философия (0.08%)", "повседневность (0.07%)", "молодежь (0.05%)", "гендерное_неравенство (0.02%)", "наука_университет (0.05%)", "соц_теория (0.07%)", "органы_власти (0.05%)", "забота (0.02%)", "здоровье_благополучие (0.05%)", "взаимодействие (0.04%)", "институциональное_доверие (0.03%)", "миграция (0.04%)", "стратификация (0.04%)", "историческая_социология (0.06%)", "семья (0.02%)"))
#try <- variation(acomp(clustdata))
#dd = as.dist(try)
#hc = hclust(dd, method="ward")

#dendextend::plot_horiz.dendrogram(hc)

#plot(hc, horiz = TRUE)

knitr::include_graphics("image_to_insert1.png")
```

---

Чем короче расстояние от темы до разбиениия на кластер, тем чаще темы со-встречаются в аннотациях статей. Получившееся разделение в некотором смысле сходится с атрибутированными темами - показательны, например, близкие ассоциации между темами "демография" и "регионы" (тема, которую, в действительности, тяжело представить себе как "важную" именно для текста аннотации) или "забота" и "семья". Более прочего понятна природа первого кластера (темы "историческая социология", "язык_дискурс", "соц_теория", "философия" и "повседневность"): его можно назвать "теоретическим" (наиболее всего эти темы представлены в журналах *"Социологическое обозрение"* и *"Вестник ТГУ"*). Другие кластеры складываются из меньшего числа тем: (1) уже упомянутые "миграция" и "регионы", (2) скорее всего, инструментальный кластер с темами "наука_университет", "методология_смешано", "методология_2_выборка", (3) темы, связанные с политическими институтами: "безопасность", "органы_власти" и "институциональное доверие", (4) "прикладные" темы, включающие "демографию" и "здоровье_благополучие", (5) стратификация - "потребление" и "стратификация", и (6) кластер тем "забота", "семья" и "гендерное_неравенство". Без близких ассоциаций остались темы "образование_школа", "молодежь", "взаимодействие" и "смешано".

 
 
Другим стандартным методом анализа соотношения тем, произведенных с CTM, является представление тем в графе, построенном на основе корреляций между ними (Lafferty & Blei, 2005; Blei & Lafferty, 2007). Для представления данного набора тем были сохранены значимые корреляции > 0.03, прочие же были приравнены к 0.


```{r, echo=F, fig.width=15, fig.height=7}
load("networkimage.RData")
#load("may22day.RData")
#mod.out.corr <- topicCorr(ctmFit24, cutoff = .03)

# output links and simplify
#links2 <- as.matrix(mod.out.corr$posadj)
#net2 <- graph_from_adjacency_matrix(links2, mode = "undirected")
#net2 <- igraph::simplify(net2) 

# create the links and nodes
#links <- igraph::as_data_frame(net2, what="edges")
#nodes <- igraph::as_data_frame(net2, what="vertices")
#V(net2)$name = c("смешано", "регионы", "язык_дискурс", "методология_смешано", "потребление", "безопасность", "демография", "образование_школа", "методология_2_выборки", "философия", "повседневность", "молодежь", "гендерное_неравенство", "наука_университет", "соц_теория", "органы_власти", "забота", "здоровье_благополучие", "взаимодействие", "институциональное_доверие", "миграция", "стратификация", "истор_соц", "семья")

#save.image("networkimage.RData")

set.seed(20657)
GGally::ggnet(net2,
      mode = "fruchtermanreingold",
      label = TRUE,
      label.size = 5,
      #group = bm$block.membership,
      #node.color = c("coral1", "black"),
      size = 1,
      weight = "degree",
      arrow.size = 4,
      legend.position = "none")
```

---

Получаемый таким образом "тематический" ландшафт дополняет результат кластеризации, приведенный выше. Кластер, связанный с государственными институтами, оказывается изолированным от прочих тем, как и "инструментальные" мотодологические темы и тема "наука_университет". Крупнейший компонет, насчитывающий 18 тем, условно состоит из наблюдаемого ранее "теоретического" кластера (к которому присоединились темы "смешано" и "взаимодействие"); прочие темы, соединяющиеся с "теоретической" частью сети можно назвать "эмпирическими". То, что эти две части причудливо связаны темой "миграции", можно связать с тем, что тема "взаимодействия" содержит лексику, применяемую для описания миграционных процессов.



Кажется важным, что доли тем в аннотациях всех журналов, разбитых по годам, практически не изменились ни для одной темы. Самым критичным стало снижение доли темы "соц_теория" после 2012 года примерно на 3% (есть соблазн найти этому внешнее объяснение, связанное, например, с программой "5-100" и повышением публикационного давления на ученых, - кажется, что написать эмпирическую статью в хороший российский журнал должно быть проще, чем теоретическую, - однако это слишком сильный тезис, требующий более внимательной проверки):


```{r, echo=F, fig.align='center'}
rm(list = ls())
load("may23day.RData")
#save.image("may23day.RData")

#rm(dfm_data, nouns_only, parts_of_speech, stm_data, to_work)
#

back_to_docs <- ctmFit24$theta %>% 
  data.frame() %>%
  `colnames<-`(c("смешано", "регионы", "язык_дискурс", "методология_смешано", "потребление", "безопасность", "демография", "образование_школа", "методология_2_выборки", "философия", "повседневность?", "молодежь", "гендерное_неравенство", "наука_университет", "соц_теория", "органы_власти", "забота", "здоровье_благополучие", "взаимодействие", "институциональное_доверие", "миграция", "стратификация", "историческая_социология", "семья")) %>% 
  bind_cols(ids) %>% 
  left_join(abstracts2, by = c("journal_name", "article_abstract")) %>% 
  
  select(-id, -article_abstract, -journal_issue, -article_name, -article_link, -author, -article_keywords, -article_doi, -abstract_lem, -abstract_lem2,
         
         -author_affiliation, -article_pages) %>% 
  mutate(year = as.numeric(year))

back_to_docs %>% 
  filter(!is.na(year)) %>% 
  #filter(journal_name == "Социологические исследования") %>% 
  select(-journal_name) %>% 
  mutate(sum = rowSums(.)) %>% 
  pivot_longer(cols = colnames(back_to_docs %>%
                                 select(-journal_name, -year)),
           names_to = "names",
           values_to = "values") %>% 
  group_by(year, names) %>%
  summarise(values = mean(values)) %>% 
  ungroup() %>%
    filter(names %in% c("соц_теория", "стратификация", "молодежь", "миграция", "институциональное_доверие", "гендерное_неравенство")) %>% 
    
  ggplot(aes(year, values, group = names, color = names)) +
  geom_line() +
  theme_minimal() +
  scale_x_continuous(limits = c(2000, 2032),
                     breaks = c(2010, 2012, 2014, 2016, 2018, 2020, 2022)) +
  scale_color_discrete(guide = 'none') +
  labs(x = "",
       y = "% документов с темой",
       title = "**Изменение частоты появления тем во всем корпусе**") +
  #geom_text(aes()) +
  theme(legend.position = "none",
        plot.title = element_markdown()) +
  geom_dl(aes(label = names), method = list(dl.trans(x = x + 0.4), "last.points", cex = 0.8)) +
  geom_dl(aes(label = names), method = list(dl.trans(x = x - 0.4), "first.points", cex = 0.8))


########## как посчитать общие изменения:

#back_to_docs %>% 
#  filter(!is.na(year)) %>% 
  #filter(journal_name == "Социологические исследования") %>% 
#  select(-journal_name) %>% 
#  mutate(sum = rowSums(.)) %>% 
#  pivot_longer(cols = colnames(back_to_docs %>%
#                                 select(-journal_name, -year)),
#           names_to = "names",
#           values_to = "values") %>% 
#  group_by(year, names) %>%
#  summarise(values = mean(values)) %>% 
#  ungroup() %>% 
#  filter(year == 2010) %>% 
#  rename(values_2010 = values) %>%
#  select(-year) %>% 
#  
#  left_join(back_to_docs %>%
#              filter(!is.na(year)) %>%
#              select(-journal_name) %>%
#              mutate(sum = rowSums(.)) %>%
#              pivot_longer(cols = colnames(back_to_docs %>%
#                                             select(-journal_name, -year)),
#                          names_to = "names",
#                          values_to = "values") %>%
#              group_by(year, names) %>%
#              summarise(values = mean(values)) %>%
#              ungroup() %>%
#              filter(year == 2022) %>% 
#              rename(values_2022 = values) %>% 
#              select(-year),
#    by = "names") %>% 
#  mutate(diff = round(values_2022 - values_2010, 2)) %>% 
#  arrange(desc(diff))
```

---


## **Размышления о результатах**


Полученные результаты описывают скорее не "разрывы" в российской социологии, а его тематический/методологический ландшафт, явленный в главных национальных дисциплинарных журналах. Финальная форма модели Wordfish указывает на то, что содержание статей все-таки можно задать с помощью оппозиции "количественного" и "качественного", однако это решение (1) сделано исключительно для журналов, т.е. без взвешивания позиций отдельных аннотаций, (2) уступает в очевидности разделения результатам немецких ученых (Schwemmer & Wieczorek, 2020, p. 12), в работе которых ассоциация между исследовательскими темами и методологиями представлена более убедительно. Можно сравнить данное выше распределение термов с тем, что получили эти авторы:


```{r, echo=F, fig.align='center'}
knitr::include_graphics("image_to_insert2.png")
```



Если брать найденную этими авторами дисциплинарную структуру за образец, то можно предположить, что российская социология сильно отличается от "мировой". В ней лишь с оговорками присутствует представленный на мировом уровне дебат "качественного" и "количественного". Однако, т. к. весь этот аргумент построен на серии смелых предположений, - в том числе, что журнальные публиакции (тексты) представляют реальную науку (о том, что для науки куда важнее неявное знание, которое невозможно передать посредством текста, сказано у многих классиков социологии науки, н. у Гарри Коллинза, см. Collins, 1974), что аннотационные данные корректно передают содержание статей (кажется, что о структуре российских аннотаций, которые в начале 2000 годов еще не являлись обязательной частью публикаций в некоторых журналах, можно было бы написать отдельно), - скорее не позволяет сделать таких предположений. Возможным объяснением отличия является то, что сам процесс написания аннотации в российской дисциплине куда менее институирован, чем в "мировых" журналах. Как было отмечено, не у всех журналов аннотация вовсе являлась обязательным элементом текста еще совсем недавно. Показательно также и то, что многие аннотации не содержат относительно подробного описания использованной методологии, что необычно в сравнении с "мировыми" журналами.


Если гипотеза об институционализации практики написания аннотации верна, то еще любопытнее становятся результаты, полученные на ранней стадии этой работы. Тогда для знакомства с моделью Wordfish были собраны аннотации выпускных квалификационных работ, написанных на бакалаврских и магистерских программах по социологии в Высшей Школе Экономики (всего было собрано 2,510 текстов). Решение модели Wordfish, примененной к этим данным, дано ниже.



```{r,echo=F, fig.align='center'}
knitr::include_graphics("image_to_insert3.png")
knitr::include_graphics("image_to_insert4.png")
```


---

При подготовке своих работ студенты находятся под надзором научных руководителей (которые могут быть заинтересованы именно в "хорошей" аннотации, ведь она, например, появится на странице преподавателя на сайте университета, и станет своеобразным сигналом о его/ее научных интересах и качестве работ, написанных под его/ее руководством, - это сигнал как для других самостоятельных членов академии, н. журнальных редакций и потенциальных соавторов, так и для будущих студентов, находящихся в поиске наставника) и под своеобразным изоморфным давлением со стороны канонов оформления аннотаций в западных журналах (которым в "Вышке" отдается явное предпочтение при составлении учебных планов). Кажется, это приводит к тому, что студенческий (!) аннотационный корпус ориентированного на западную академию института оказывается более похож на картину, продемонстрированную немецкими авторами.



Полученные в результате моделирования тем представляют скорее дескриптивный интерес и, безусловно, требуют валидации от участников поля (н. аффилированных с журналами социологов, понимающих реальное содержание публикуемых статей). Сравнивать выбранное число тем и их состав с результатами прошлых исследованиях аннотаций социологических статей (Giordan et al., 2018; Daoud & Kohl, 2015) трудно, т. к. каждое исследование имело свой собственный текстовый корпус со всеми его уникальными особенностями. В случае данного исследования определенным препятствием в интерпретации результатов стало то, что один из журналов, *"Вестник ТГУ"*, посвящен не только социологии, и некоторые аргументы (лексика) из него удивительным образом пересекалась с лексикой из других тем, внося в них некоторый шум. Также важным ограничением моделирования тем на имеющемся корпусе является то, что, как утверждалось выше, написание аннотации в контексте российской социологии не является институированной практикой. При всем этом моделирование тем подтверждает пусть очевидную, но оппозицию между теоретическими и эмпирическими работами, и вскрывает некоторые неочевидные тематические кластеры (н. тот, что связан с изучением государственных институтов).




### **p.s. что еще хочется успеть**


  - построить более "корректную" финальную модель Wordfish: сейчас она выполнена без учета коллокаций;
  
  
  - **привести в порядок метаданные статей и сопоставить полученные темы с, например, авторскими аффилиациями и числом соавторов;**
  
  
  - еще раз посмотреть на CTM с другими значениями k: вероятно, можно получить более интерпретируемое решение, которое я упустил;
  
  
  - **собрать аннотации для пропущенных годов - в первую очередь, это относится к *"СоцИсу"* за 2010-2013 годы.**


## **Библиография**



Blei, D. M., & Lafferty, J. D. (2007). A correlated topic model of science.



Collins, H. M. (1974). The TEA set: Tacit knowledge and scientific networks. Science studies, 4(2), 165-185.



DiMaggio, P., Nag, M., & Blei, D. (2013). Exploiting affinities between topic modeling and the sociological perspective on culture: Application to newspaper coverage of US government arts funding. Poetics, 41(6), 570-606.


Daenekindt, S., & Huisman, J. (2020). Mapping the scattered field of research on higher education. A correlated topic model of 17,000 articles, 1991–2018. Higher Education, 80(3), 571-587.



Daoud, A., & Kohl, S. (2015). Is there a New Economic Sociology Effect? A Topic Model on the Economic Orientation of Sociology, 1890 to 2014.



Giordan, G., Saint-Blancat, C., & Sbalchiero, S. (2018). Exploring the history of American sociology through topic modelling. Tracing the Life Cycle of Ideas in the Humanities and Social Sciences, 45-64.


Lafferty, J., & Blei, D. (2005). Correlated topic models. Advances in neural information processing systems, 18.


Lindstedt, N. C. (2019). Structural topic modeling for social scientists: A brief case study with social movement studies literature, 2005–2017. Social Currents, 6(4), 307-318.


Martin, F., & Johnson, M. (2015, December). More efficient topic modelling through a noun only approach. In Proceedings of the Australasian Language Technology Association Workshop 2015 (pp. 111-115).



Roberts, M. E., Stewart, B. M., & Tingley, D. (2019). Stm: An R package for structural topic models. Journal of Statistical Software, 91, 1-40.


Schwemmer, C., & Wieczorek, O. (2020). The methodological divide of sociology: Evidence from two decades of journal publications. Sociology, 54(1), 3-21.


Segalovich, I. (2003). A fast morphological algorithm with unknown word guessing induced by a dictionary for a web search engine. MLMTA, 2003, 273.


Slapin, J. B., & Proksch, S. O. (2008). A scaling model for estimating time‐series party positions from texts. American Journal of Political Science, 52(3), 705-722.


Van den Boogaart, K. G., & Tolosana-Delgado, R. (2013). Analyzing compositional data with R (Vol. 122, pp. 1-200). Berlin: Springer.


Wang, Y., Bowers, A. J., & Fikis, D. J. (2017). Automated text data mining analysis of five decades of educational leadership research literature: Probabilistic topic modeling of EAQ articles from 1965 to 2014. Educational administration quarterly, 53(2), 289-323.


Westgate, M. J., Barton, P. S., Pierson, J. C., & Lindenmayer, D. B. (2015). Text analysis tools for identification of emerging topics and research gaps in conservation science. Conservation Biology, 29(6), 1606-1614.
